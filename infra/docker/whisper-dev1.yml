# TermiteTowers Continuous Code Management Header TEMPLATE
# % ccm_modify_date: 2025-08-31 11:51:01 %
# % ccm_author: mpegg %
# % ccm_author_email: mpegg@hotmail.com %
# % ccm_repo: https://github.com/mpegg007/TermiteTowers.git %
# % ccm_branch: dev1 %
# % ccm_object_id: infra/docker/whisper-dev1.yml:0 %
# % ccm_commit_id: unknown %
# % ccm_commit_count: 0 %
# % ccm_commit_message: unknown %
# % ccm_commit_author: unknown %
# % ccm_commit_email: unknown %
# % ccm_commit_date: 1970-01-01 00:00:00 +0000 %
# % ccm_file_last_modified: 2025-08-31 10:26:18 %
# % ccm_file_name: whisper-dev1.yml %
# % ccm_file_type: text/plain %
# % ccm_file_encoding: us-ascii %
# % ccm_file_eol: CRLF %
# % ccm_path: infra/docker/whisper-dev1.yml %
# % ccm_blob_sha: 91937b6afd6d99adde4855d0f2d30a91de35008a %
# % ccm_exec: no %
# % ccm_size: 2395 %
# % ccm_tag:  %
# tt-ccm.header.end
# yaml-language-server: $schema=https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json
name: whisper-dev1

services:
  whisper-faster:
    image: nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04
    container_name: whisper_faster-dev1
    working_dir: /app
    user: "${UID_SVC:-2001}:${GID_TT_AI:-1006}"
    volumes:
      - ../source:/app
      - ../audio:/app/audio
      - ../output:/app/output
      - /mnt/ai_storage/models/whisper:/app/models
      - /mnt/ai_storage/models/huggingface:/cache/huggingface
      - /mnt/ai_storage/models/pip:/cache/pip
      - /mnt/ai_storage/models/torch:/cache/torch
    command: >
      bash -lc "umask 002 && apt-get update &&
               apt-get install -y python3.10 python3.10-venv python3.10-dev python3-pip git ffmpeg libsndfile1 &&
               update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 &&
               python3 -m pip install --upgrade pip &&
               python3 -m pip install torch torchvision torchaudio &&
               python3 -m pip install faster-whisper &&
               python3 /app/transcribe.py --input_dir /app/audio --output_dir /app/output --model_dir /app/models --model_size medium --device cuda --compute_type float16"
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/cache/huggingface
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

